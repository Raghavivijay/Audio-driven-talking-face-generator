# Audio-driven-talking-face-generator
The Audio-Driven Talking Face Generator project uses deep learning to create realistic facial animations from recorded speech. By employing a Conditional Variational Autoencoder (cVAE), it generates speaker-independent animations that capture lip movements and emotions, enhancing user engagement in applications like gaming and virtual reality.
